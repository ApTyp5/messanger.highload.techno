Курсовой проект "мессенджер"
==========

Аудитория: 
---------
50 млн человек по России [(половина пользователей телеграмма 4 года назад)](https://telegram.org/blog/100-million)

Планируемые нагрузки:
----------------
[100 миллионов пользователей](https://telegram.org/blog/100-million) были способны создавать нагрузку в 
[15 миллиардов запросов](https://telegram.org/blog/15-billion) в сутки

Следовательно для 50 млн пользователей нагрузка будет равна 
(15 * 10^12) / 2 = __7.5 * 10^12 (request per day)__

Но нагрузка распределена не равномерно, в соответствии со [статистикой](https://popsters.ru/blog/post/aktivnost-auditorii-v-socialnyh-setyah-issledovanie-2019) 
в пиковый час телеграм обрабаывает 4,5 % дневного трафика.

Следовательно, в пик нагрузки сервису приходится обрабаывать 
(7.5 * 10^12 * 4,5%) / 100% = __3 375 * 10^8 (rph)__

Предположив,что в течение часа/минуты нагрузка распределяется равномерно, расчитаем более точную нагрузку на сервис: 
```
  3 375 * 10^8 (request per hour) =
  = 56,25 * 10^8 (rpm) =
  = 93,75 * 10^6 (rps)
```


Учитывая, что в худшем случае каждому сообщению будет соответствовать запрос полученных сообщений пользователя то: 

1. Отправка сообщений займет _93,75 * 10^6 ~= 100 * 10^6_
2. Запрос полученных сообщений = _93,75 * 10^6 ~= 100 * 10^6_

В течение пикового часа возможны возникновения локальных пиков нагрузок, под которые следует выделить 

1. 2 * 100 * 10^6 = 200 * 10^6 на запись
1. 2 * 100 * 10^6 = 200 * 10^6 на чтение


Идея функционирования сервиса:
--------------------
1. К к каждому пользователю формируется очередь сообщений;
2. Пользователь может в любой момент вычитать пришедшие к нему сообщения;
3. История сообщений хранится на клиентах.


Схема бд:
--------------------
![Схема бд](https://github.com/ApTyp5/messanger.highload.techno/blob/main/schem.jpg)




Выбор конкретной СУБД
-----------------------------
В качестве СУБД выбрана Redis благодаря следующим характеристикам:
1. Репликация из коробки;
2. Мастабируемость из коробки;
3. Встроенная работа со списками.


Физическая особенность хранения очередей сообщений:
1. На каждого пользователя выделяется список, ключом которого является id пользователя.
2. В списке хранятся строковые записи.
3. Каждое отдельное сообщение состоит из 3-х элементов списка (id автора, timestamp, text).
4. После считывания очередь удаляется.


Кластеризация: шардинг, репликация 
----------------------------
 * Шардинг будет производиться по полю user_id;
 * Каждого мастера будут страховать 2 слейва;
 * Конфигурация кластера хранится на каждой из нод.
 
 
 


Замеры времени вставки одного сообщения
------------------------------
![Замеры вставки одного сообщения](https://github.com/ApTyp5/messanger.highload.techno/blob/main/insert-bench.png)

Длина сообщения была равна 35 русских символов c пробелами, что соответствует 
[средней длине сообщения человека в возрасте 25 лет](https://crushhapp.com/blog/k-wrap-it-up-mom).

Округлим до 30 000 rps


Замеры времени получения одной очереди сообщений
------------------------------------ 
![Замеры вставки одного сообщения](https://github.com/ApTyp5/messanger.highload.techno/blob/main/read-bench.png)

В очереди сообщений при замерах находится 20 писем.

Округлим до 30 000 rps.


Выбор прочих технологий:
-------------------------------
1. ЯП: golang. Преимущества: быстрая разработка, встроенная многопоточность, большое сообщество.
2. Фреймворк: echo. Преимущества: популярный, простой фреймворк с хорошей документацией.
2. Протоколы взаимодействия: https при установлении соединения, после wss. Преимущества второго: позволяет 
реализовать real-time отправку сообщений наиболее естественным образом, без хаков вроде long polling.
3. Веб-сервер: nginx. Так как он обладает высокой проиводительностью и легко настраиваем.


Информация об эффективности Appliction серверов:
------------------------------------
Судя по [исследованиям](https://github.com/smallnest/go-web-framework-benchmark), прокидывание запросов к СУБД из golang и последующий возврат ответа
даёт в среднем результаты 30 000 rps.


Балансировщики нагрузки:
--------------------------------------
Исходя из [исследований](https://github.com/NickMRamirez/Proxy-Benchmarks), nginx (обоснование позже) проксирует запросы 
на сервера с ёмкостью 29 000rps.

Да, балансировщики нужны только для того, чтобы перенаправить изначальный зарпос на app-сервер, который уже после будет держать
wss-соединение, но мы рассмотрим худший случай, когда все пользователи решили подключиться к сервису в один момент. При этом запомним,
что посчитали нагрузку балансировщиков с большим запасом, что будет означать, что запасные балансеры нам не нужны.

Особенности балансировки: DNS отдают адреса балансировщиков по round-robin с ttl 5min. таким образом при выходе из строя одного балансировщика
достаточно будет удалить его из записей DNS. Ситуация выхода из строя балансировщиков будет мониториться heartbeat-демонами на DNS серверах.

Терминация SSL происходит на балансировщиках.


Требуемое количество ядер для различных категорий машин
----------------------------------------

|Категория|Вычисления|Количество ядер|
|---------|----------|:---------------:|
|Мастер-ноды|(200 * 10^6 rps) / (30 * 10^3 rps)|6 667|
|Слейв-ноды|<количество ядер на master-node> * 2|неизвестно|
|App-серверы|(400 * 10^6 rps) / (30 * 10^3 rps)|13 334|
|Balancers|(400 * 10^6 rps) / (29 * 10^3 rps)|13 794 (учитывая запас)|






Взаимодействие всех частей в целом:
--------------------------------
Концептуально сервис будет работать следующим образом
![Схема бд](https://github.com/ApTyp5/messanger.highload.techno/blob/main/alll.jpg)






Итог оснащения Сервиса:
-------------------------------
1. СУБД, шарды. 2 ядра 16 Гб памяти. 60 серверов.
2. СУБД, конфиг. 2 ядра 8 Гб памяти. 3 сервера.
2. App. 4 ядра 8 Гб памяти. 6 серверов.
3. Balance. 4 ядра 8 Гб памяти. 6 серверов.
4. DNS сервер. 4 ядра 8 Гб памяти. 2 сервера.




Облачный провайдер:
--------------------------------
Google Cloud, так как позволяет быстро и гибко настроить весь сервис, ближайший датацентр в Стокгольме построен по стандарту tier IV. 
Также даёт возможность быстро расшириться под нагрузку при всплеске нагрузки и размещать сервера по разным зонам.


Расположение серверов, устойчивость к сбоям, всплескам нагрузки:
--------------------------------
Сервера будут равномерно распределены по зонам a,b,c. Причем также равномерно должны быть распределены сервера в пределах шарда.
Таким образом при выходе из строя одной зоны сервис не выйдет из строя - в шардах будут выбраны новые primary ноды, 
вышедшие из строя балансировщики будут удалены из DNS записей, упавшие application сервера будут игнорироваться балансировщиками.
Поэтому сервис останется доступным. 

Рассчеты специально проводились на минимальных ресурсах, что и выражено в требованиях по оборудованию.
Поэтому, если сервис не сможет выдерживать предполагаемую нагрузку (или нагрузка станет больше предполагаемой), то
в этом случае можно будет быстро и дешево произвести вертикальное масштабирование. Таким образом снизятся непредвиденные затраты
и у людей будет больше времени на устранение недостатков.










